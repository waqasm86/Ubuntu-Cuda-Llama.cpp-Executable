.:
bin
include
lib
LICENSE
llama-cpp-cuda-files-folders.txt
README-CUDA.txt

./bin:
convert_hf_to_gguf.py
gemma-3-1b-it-Q4_K_M.gguf
llama-batched
llama-batched-bench
llama-bench
llama-cli
llama-convert-llama2c-to-ggml
llama-cvector-generator
llama-diffusion-cli
llama-embedding
llama-eval-callback
llama-export-lora
llama-finetune
llama-gen-docs
llama-gguf
llama-gguf-hash
llama-gguf-split
llama-gritlm
llama-imatrix
llama-lookahead
llama-lookup
llama-lookup-create
llama-lookup-merge
llama-lookup-stats
llama-mtmd-cli
llama-parallel
llama-passkey
llama-perplexity
llama-quantize
llama-retrieval
llama-run
llama-save-load-state
llama-server
llama-server.sh
llama-simple
llama-simple-chat
llama-speculative
llama-speculative-simple
llama-tokenize
llama-tts
test-arg-parser
test-autorelease
test-backend-ops
test-barrier
test-chat
test-chat-parser
test-chat-template
test-gbnf-validator
test-gguf
test-grammar-integration
test-grammar-parser
test-json-partial
test-json-schema-to-grammar
test-llama-grammar
test-log
test-model-load-cancel
test-mtmd-c-api
test-quantize-fns
test-quantize-perf
test-quantize-stats
test-regex-partial
test-rope
test-sampling
test-thread-safety
test-tokenizer-0
test-tokenizer-1-bpe
test-tokenizer-1-spm

./include:
ggml-alloc.h
ggml-backend.h
ggml-blas.h
ggml-cann.h
ggml-cpp.h
ggml-cpu.h
ggml-cuda.h
ggml.h
ggml-metal.h
ggml-opt.h
ggml-rpc.h
ggml-sycl.h
ggml-vulkan.h
ggml-webgpu.h
gguf.h
llama-cpp.h
llama.h
mtmd.h
mtmd-helper.h

./lib:
cmake
libggml.a
libggml-base.a
libggml-cpu.a
libggml-cuda.a
libllama.a
libmtmd.a
pkgconfig

./lib/cmake:
ggml
llama

./lib/cmake/ggml:
ggml-config.cmake
ggml-version.cmake

./lib/cmake/llama:
llama-config.cmake
llama-version.cmake

./lib/pkgconfig:
llama.pc
